%% this chapter sets up the foundational system, which is Univalent Foundations

\section{What is a type?}

In some computer programming languages, all variables are introduced along with a declaration of the type of thing they will refer to.  For example,
one may encounter types such as $bool$, $string$, $int$, and $real$, describing Boolean values, character strings, 32 bit integers, and 64 bit
floating point numbers.  The types are used to determine which statements of the programming language are grammatically well-formed.
For example, if $s$ of type $string$ and $x$ is of type $real$, we may write $1/x$, but we may not write $1/s$.

Types occur in mathematics, too, and are used in the same way: all variables are introduced along with a declaration of the type of thing they
will refer to.  For example, one may say ``consider a point $P$ of the plane'', ``consider a line $L$ of the plane'', ``consider a hexagon
$H$'', or ``consider a graph $G$''.  The types are used to determine which mathematical statements are grammatically well-formed.  For example,
one may write ``$P$ lies on $L$'' or ``$L$ passes through $P$'', but not ``$L$ lies on $P$''.

In {\em univalent mathematics}, types are used to classify all mathematical objects.  Every mathematical object is an element of some (unique)
type.

One expresses the statement that an ``element'' $a$ is of ``type'' $X$ by writing $a:X$.  Using that notation, each variable is introduced along
with a declaration of the type of thing it will refer to, and the declared types of the variables are used to determine which statements of the
theory are grammatically well-formed.

There are enough ways to form new types from old ones to provide everything we need to write mathematics.

If $X$ and $Y$ are types, there will be a type whose elements serve as {\em functions} from $X$ to $Y$; the notation for it is $X \to Y$.  Thus
when we write $f : X \to Y$, we mean that $f$ is an element of the type $X \to Y$, and we are saying that $f$ is a function from $X$ to $Y$.

Functions behave as one would expect, and one can make new ones in the usual way.

To provide an example of making new functions in the usual way, consider functions $f : X \to Y$ and $g : Y \to Z$.  We define their composite
$g \circ f : X \to Z$ by setting $g \circ f \defeq (a \mapsto g(f(a)))$.  Such definitions are to be regarded as syntactically transparent in
our formal system, in the sense that two formal expressions will be regarded as being {\em the same by definition} if they yield the same formal
expression after the definitions of all the symbols within them are completely expanded.  Given two expressions that are the same by definition,
we may replace one with the other in any other expression, at will.  Here is an example: consider functions $f : X \to Y$, $g : Y \to Z$, and $h
: Z \to W$.  Then $(h \circ g) \circ f$ and $h \circ (g \circ f)$ are the same by definition, since applying the definitions within expands both
to $a \mapsto h(g(f(a)))$.

One may define the identity function $id_X : X \to X$ by setting $id_X \defeq (a \mapsto a)$.  Application of definitions shows that $f \circ
id_X$ is the same as $a \mapsto f(a)$, which, by convention, is to be regarded as the same as $f$.  A similar computation applies to $id_Y \circ
f$.

In the following sections we will expose various other elementary types and elementary ways to make new types from old ones.

\section{The type of natural numbers}\label{nat}

Here are Peano's rules \citep{peano-principia} for constructing the natural numbers in the form that is used in type theory.
\begin{enumerate}
\item[P1:] there is a type called $\NN$ (whose elements will be called natural numbers);
\item[P2:] there is an element of $\NN$ called $0$;
\item[P3:] if $m$ is a natural number, then there is also a natural number $S(m)$, called the {\em successor} of $m$;
\item[P4:] given a family of types $X(m)$ depending on a parameter
  $m$ of type $\NN$, in order to define a family $f(m) : X(m)$ of elements of each of them it suffices to provide an element $a$ of $X(0)$ and
  to provide, for each $m$, a function $g_m : X(m) \to X(S(m))$.  (The resulting function $f$ may be regarded as having been defined inductively
  by the two declarations $f(0) \defeq a$ and $f(S(m)) \defeq g_m(f(m))$.)
\end{enumerate}
\nopagebreak
You may recognize rule P4 as ``the principle of mathematical induction'' or as ``defining a function by recursion''.  We may also refer to it
simply as ``induction for $\NN$''.  Notice that the two cases in an inductive definition correspond to the two ways of introducing elements of
$\NN$ via the use of rules P2 and P3.

Here is an example of defining a function by recursion using induction for $\NN$.  We define the factorial function $f : \NN \to \NN$ by
defining $X(m)$ to be $\NN$ for all $m$ and by setting $f(0) \defeq 1$ and setting $f(S(m)) \defeq (m+1) \cdot f(m)$.  One can infer that the
function $g_m$ of rule (P4) is $n \mapsto (m+1) \cdot n$.

We introduce the following definitions.
\begin{align*}
 1 & \defeq S(0) \\
 2 & \defeq S(1) \\
 3 & \defeq S(2) \\
 4 & \defeq S(3)
\end{align*}

We may use induction to define the sum $m+n$ of two natural numbers, as a natural number.  We handle the two possible cases for the argument $m$
as follows: we define $0+n \defeq n$, and we define $(S(m))+n \defeq S(m+n)$.  Application of definitions shows, for example, that $2+2$ and $4$
are the same by definition, because they both reduce to $S(S(S(S(0))))$.

Before we can write an equation such as $2+2=4$, we must introduce a formal treatment of equality in type theory.  We do that in the next section.

\section{Identity types}\label{paths}

One of the most important types is the {\em identity type}, which implements the intuitive notion of equality; the reader may be more
comfortable if we call it the {\em equality type}, at least initially.  Identity (or equality) between two elements may be considered only when
the two elements are of the same type; we shall have no need to compare elements of different types.

Here are the rules for constructing equality types.
\begin{enumerate}
\item[E1:]
  for any type $X$ and for any elements $a$ and $b$ of it, there is a type $a=b$;
\item[E2:] for any type $X$ and for any element $a$ of it, there is an element $\refl a$ of type $a=a$ (the name $\refl{}$ comes from the word
  ``reflexivity'')
\item[E3:] for any type $X$ and for any element $a$ of it, given a family of types $P(b,e)$ depending on parameters $b$ of type $X$ and $e$ of type
  $a=b$, in order to define elements $f(b,e) : P(b,e)$ of all of them it suffices to provide an element $p$ of $P(a,\refl a)$.  The resulting
  function $f$ may be regarded as having been completely defined by the single definition $f(a,\refl a) \defeq p$.
\end{enumerate}

An element of $a=b$ can be thought of, for now, as a ``proof'' that $a$ is equal to $b$.

We see from rule E2 that $\refl{S(S(S(S(0))))}$ serves as a proof of $2+2=4$, as do $\refl 4$ and $\refl{2+2}$.  A student might wish for a
more detailed proof of that equation, but as a result of our convention above that definitions are syntactically transparent, the application of
definitions, including inductive definitions, is regarded as a trivial operation.

We will refer to rule E3 as ``induction for equality''.  It says that to prove something about (or to construct something from) every proof that
$a$ is equal to something else, it suffices to consider the special case where the proof is the trivial proof that $a$ is equal to itself, i.e.,
where the proof is $\refl a : a=a$.  Notice that the single case in such an induction corresponds to the single way of introducing elements of
equality types via rule E2, and compare that with P4, which dealt with the two ways of introducing elements of $\NN$.
%% ???
Intuitively, the induction principle for equality amounts to saying that the element $\refl a$ ``generates'' the system of types $a=b$, as $b$
ranges over elements of $A$.

We may use induction to prove symmetry of equality.  In accordance with our discussion of implication above, we show how to produce an element
of $b=a$ from an element $p$ of $a=b$, for any $b$ and $p$.  By induction (letting $P(b,e)$ be $b=a$ for any $b$ of type $X$ and for any $e$ of
type $a=b$, for use in rule E3 above), it suffices to produce an element of $a=a$; we choose $\refl a$ to achieve that.

Transitivity of equality is established the same way.  For each $a,b,c:X$ and for each $p:a=b$ and for each $q:b=c$ we want to produce an
element of type $a=c$.  By induction on $q$ we are reduced to the case where $c$ is $b$ and $q$ is $\refl b$, and we are to produce an element
of $a=b$.  The element $p$ serves the purpose.  Notice the similarity of this inductive definition with the definition given above of the sum
$m+n$.

Now we state our symmetry result a little more formally.

\begin{definition}
  For any type $X$ and for any $a,b:X$, let $\symm_{a,b} : (a=b) \to (b=a)$ be the function defined by induction by setting 
  $\symm_{a,a}(\refl a) \defeq \refl a$.
\end{definition}

Similarly, transitivity is formulated as an inductive definition for a function $\trans_{a,b,c} : (a=b) \to ((b=c) \to (a=c))$.  We may
abbreviate $(\trans_{a,b,c}(p))(q)$ as $p*q$.

Associativity of transitivity is formulated and established similarly.  We leave that as an exercise.

One frequent use of elements of identity types is in {\em substitution}.  Let $X$ be a type, and let $T(x)$ be a family of types depending on a
parameter $x:X$.  Suppose $x,y:X$ and $e:x=y$.  Then there is a function of type $T(x) \to T(y)$. We define one specific such function by induction, by taking its value
to be the identity function on $T(x)$ in the case of $\refl{x}:x=x$.
\begin{definition}\label{def:transport} The function
\[ 
\trp : \prod_{X:\Type} \prod_{T: X\to \Type} \prod_{x,y:X} (x=y \to T(x) \to T(y))
\]
is defined by putting $\trp(X,T,x,x,\refl{x})\defeq \id_{T(x)}$.
\end{definition} 
The function thus defined is called (in full)
\emph{the transport function in the type family $T$ along the path $e$},
We often use less verbose phrases such as `by transport'
and simplified the notation to $\trp^T e$, or even just $\trp e$.
The precise expressions should always be easy to recover from the context.

\section{Other types}

There are other examples of types that are conveniently presented as inductive definitions, in the style we have seen with the natural numbers
and the equality types.  We present three examples.

Firstly, there is the ``empty'' type, called $\emptyset$, defined inductively, with no way to construct elements provided in the inductive
definition.  The inductive principle for $\emptyset$ says that to prove something about (or to construct something from) every element of
$\emptyset$, it suffices to consider no special cases (!).  Hence, every statement about an arbitrary element of $\emptyset$ can be proven. (This is called the Ex Falso
rule in traditional logic.) As
an example, we may prove that any two elements $x$ and $y$ of $\emptyset$ are equal by using induction on $x$.

An element of $\emptyset$ will be called an {\em absurdity}, and the negation $\neg P$ of a proposition $P$ will be implemented as the function
type $P \to \emptyset$.  This is sensible, because an element of $\neg P$ could be applied to an element of $P$ to produce an element of
$\emptyset$, i.e., an absurdity.

Another appropriate name for $\emptyset$ is $\false$.

We may also construct a function $\false \to X$, for any type $X$, by induction, showing that from an absurdity anything follows.

To encode the property that $X$ has no elements we use the type $X \to \emptyset$.  To encode the property that elements $a,b:X$ are not equal,
we use the type $(a=b) \to \emptyset$, and we let $a \ne b$ denote it.

Secondly, there will also be a type called $\true$, defined inductively and provided with a single element $\triv$; (the name $\triv$ comes from the word
  ``trivial'').  Its induction principle
states that, in order to prove something about (or to construct something from) every element of $\true$, it suffices to consider the special
case where the element is $\triv$.  As an example, we may prove, for any element $u : \true$, that $u=\triv$, by using induction to reduce
to proving $\triv=\triv$, a proof of which is provided by $\refl{\triv}$.  One may also prove that any two elements of $\true$ are equal by using induction twice.

There is a function $X \to \true$, for any type $X$, namely: $a \mapsto \triv$.  This corresponds, for propositions, to the statement that an
implication holds if the conclusion is true.

Thirdly, there will be a type called $\bool$, defined by induction and provided with two elements, $\yes$ and $\no$.  One may prove by induction
that any element of $\bool$ is equal to $\yes$ or to $\no$.

We may use substitution to prove $\yes \ne \no$.  To do this, we introduce a family of types $P(b)$ parametrized by a variable $b:\bool$.
Define $P(\yes) \defeq \true$ and define $P(\no) \defeq \false$.  The definition of $P(b)$ is motivated by the expectation that we will be able
to prove that $P(b)$ and $b = \yes$ are equivalent.  If there were an element $e: \yes = \no$, we could substitute $\no$ for $\yes$ in $\triv :
P (\yes)$ to get an element of $P(\no)$, which is absurd.  Since $e$ was arbitrary, we have defined a function $(\yes=\no) \to \emptyset$,
establishing the claim.

In the same way, we may use substitution to prove that successors of natural numbers are never equal to $0$, i.e., for any $n:\NN$ that $0 \ne
S(n)$.  To do this, we introduce a family of types $P(i)$ parametrized by a variable $i:\NN$.  Define $P$ recursively by specifying that $P(0)
\defeq \true$ and $P(S(m)) \defeq \false$.  The definition of $P(i)$ is motivated by the expectation that we will be able to prove that $P(i)$
and $i = 0$ are equivalent.  If there were an element $e: 0 = S(n)$, we could substitute $S(n)$ for $0$ in $\triv : P ( 0 )$ to get an element
of $P(S(n))$, which is absurd.  Since $e$ was arbitrary, we have defined a function $(0=S(n)) \to \emptyset$, establishing the claim.

There are {\em sums} of types.  By this we mean if $X$ is a type and $Y(x)$ is a family of types indexed by a parameter $x$ of type $X$, then
there will be a type $\sum _{x:X} Y(x)$ whose elements are all pairs $(a,b)$, where $a:X$ and $b:Y(a)$.  We may refer to $X$ as the {\em index
  type} of the sum.  Sums may be implemented by an inductive definition.   (FILL IN SOME PROPERTIES.)

Given a function $f : X \to Y$ and an element $y:Y$, the {\em fiber} (or {\em inverse image}) $f^{-1}(y)$ consists of points $x$ such that $f(x)
= y$.  This is encoded by defining $f^{-1}(y) \defeq \sum_{x:X} (f(x) = y)$.  In other words, a point of the fiber is a pair $(x,e)$ consisting
of the point $x$ and an element $e$ of the identity type $f(x) = y$.

There is a binary sum operation on types: for any types $X$ and $Y$, there is a type $X \amalg Y$.  It is also called the {\em disjoint union}
of $X$ and $Y$.  From an element of $X$ or an element of $Y$ we can produce an element of $X \amalg Y$.  The binary sum is implemented by an
inductive definition with two constructors: $\inl{} : X \to X \amalg Y$ and
$\inr{} : Y \to X \amalg Y$. Proving a property of any element of $X \amalg Y$
means proving that this property holds of any $\inl{x}$ with $x:X$ and any
$\inr{y}$ with $y:Y$. (ADD COMPUTATIONAL RULE)

Our type theory will also contain {\em products} of types.  By this we mean if $X$ is a type and $Y(x)$ is a family of types indexed by a
parameter $x$ of type $X$, then there will be a type $\prod _{x:X} Y(x)$ whose elements $f$ are functions that provide elements $f(a)$ of type
$Y(a)$, one for each $a:X$.  A function $f : X \to Y$ is essentially the same thing as a function $f$ of $\prod_{x:X} Y$, where the product is
formed using a constant family of types.  (FILL IN SOME PROPERTIES.)

There is a binary product operation on types: for any types $X$ and $Y$, there is a type $X \times Y$.  From an element of $X$ and an element of
$Y$ we can produce an element $(x,y)$ of $X \times Y$.  The binary product is implemented as a special case of sums.  (SAY MORE AND FILL IN SOME
PROPERTIES.)

Let $X$ be a type.  The property that $X$ has exactly one element may be expressed by saying $X$ has an element such that every other element is
equal to it.  Hence it is encoded by the type $\sum_{a:X} \prod_{b:X} (a=b)$.

\section{Propositions and sets}

Let $X$ be a type.  The property that $X$ has at most one element is equivalent to the property that any two elements are equal, so is encoded
by $\prod_{a,b:X} (a=b)$.  We shall call such a type a {\em proposition}, and its elements will be called {\em proofs}.
Alternatively, we shall say that $X$ has level {\em at most 1}.

Let $X$ be a type.  If for any $x:X$ and any $y:X$ the identity type $x=y$ is a proposition, then we shall say that $X$ is a {\em set}.
Alternatively, we shall say that $X$ has level {\em at most 2}.

Let $X$ be a type.  If for any $x:X$ and any $y:X$ the identity type $x=y$ is a set, then we shall say that $X$ has level {\em at most 3}.

The pattern continues.  If for any $n:\NN$, any $x:X$, and any $y:X$ the identity type $x=y$ is of level at most $n$, then we shall say that $X$
has level {\em at most $n+1$}.

For this terminology to make sense we must have that every type of level
at most 1 is also a type of level at most 2. From this it follows
that the levels are cumulative. Therefore we prove the following lemma.

\begin{lemma}\label{lem:prop_is_set}
Every type that is a proposition is also a set.
\end{lemma}
\begin{proof}
Let $X$ be a type and let $f: \prod_{a,b:X} (a=b)$. Let $a,b,c : X$ and
let $P(x)$ be the type $a=x$ depending on $x:X$. Then
$f(a,b):P(b)$ and $f(a,c):P(c)$. By path induction we prove for
all $q:b=c$ that $q\cdot f(a,b) = f(a,c)$. For this it suffices to
verify that $\refl{b} \cdot f(a,b) = f(a,b)$, which follows immediately.
So $q$ is equal to $f(a,c)\cdot f(a,b)^{-1}$ which doesn't
depend on $q$, so all such $q$ are equal. Hence $X$ is a set.
\end{proof}

In the following lemma we collect a number of useful results on propositions.

\begin{lemma}\label{lem:prop_utils}
Let $A$ be a type, and let $P$ and $Q$ propositions.
Let $R(a)$ be a proposition depending on $a:A$. Then we have:
\begin{enumerate}
\item\label{prop_utils_false_true} $\false$ and $\true$ are propositions;
\item\label{prop_utils_implication} $A\to P$ is a proposition;
\item\label{prop_utils_pi} $\prod_{a:A} R(a)$ is a proposition;
\item\label{prop_utils_times} $P\times Q$ is a proposition;
\item\label{prop_utils_eq} $P = Q$ is a proposition.
\end{enumerate}
\end{lemma}

\begin{proof}
If $p,q : \false$, then $p=q$ is proved by the Ex Falso rule.
If $p,q : \true$, then $p=q$ is proved by double induction,
which reduces the proof to observing that $\refl{\triv}: \triv=\triv$.
If $p,q : A\to P$, then $p=q$ is proved by first observing that $p$ and $q$
are functions. Hence by function extensionality they are equal if pointwise
equal, which is the case since $P$ is a proposition.
If $p,q : \prod_{a:A} R(a)$ one can use the same argument as for $A\to P$
but now with \emph{dependent} functions $p,q$.
If $(p_1,q_1),(p_2,q_2) : P\times Q$, then $(p_1,q_1)=(p_2,q_2)$
is proved componentwise. By univalence, $P = Q$ is equivalent to
$(P\to Q)\times(Q\to P)$, which is a proposition by 
combining (\ref{prop_utils_implication},\ref{prop_utils_times})
\end{proof}

Several remarks can be made here. First, the lemma supports the
use of $\false,\true$ as truth values, and the use of 
$\to,\prod,\times$ for implication, universal quantification,
and conjunction, respectively. Since $\false$ is a proposition,
it follows by (\ref{prop_utils_implication}) above that 
$\neg A$ as defined by $A\to\false$ is a proposition for any type $A$.
As noted before, (\ref{prop_utils_implication}) is a
special case of (\ref{prop_utils_pi}).

Notably absent in the lemma above are disjunction
and existential quantification. This has a simple reason:
$\true\amalg \true$ has the distinct elements 
$\inl{\triv}$ and $\inr{\triv}$, an is therefore \emph{not} a proposition. 
Similarly, $\sum_{n:\NN} \true$ has infinitely many 
distinct elements $(n,\triv)$ and is not a proposition. We will see later how
to work with disjunction and existential quantification for propositions.

DO SOMETHING WITH THIS TEXT HERE: In the case where each $P(a)$ is a proposition (to be defined later), we may say that the truth of $P(a)$ is
invariant under substitution of an equal element for $a$.  In other words, equal elements of $X$ have the same properties.  In the case where each $P(a)$ is not assumed to
be a proposition, and thus its elements are ways to add extra structure to $a$, we may say that the structures can be {\em transported} from $a$
to $b$ by the proof $e$ of equality.

The lemma above has a generalization from propositions to
types of level at most $n$ which we state without proving.

\begin{lemma}\label{lem:level_n_utils}
Let $A$ be a type, and let $X$ and $Y$ be types of level at most $n$.
Let $Z(a)$ be a type of level at most $n$ depending on $a:A$. Then we have:
\begin{enumerate}
\item\label{level_n_utils_implication} $A\to X$ is a type of level at most $n$;
\item\label{level_n_utils_pi} $\prod_{a:A} Z(a)$ is a type of level at most $n$;
\item\label{level_n_utils_times} $X\times Y$ is a type of level at most $n$.
\end{enumerate}
\end{lemma}

\section{Logical operations on propositions}

\section{Propositional truncation; disjunction}

\section{Operations on sets that produce new sets}

\begin{lemma}\label{lem:subset}
Let $S$ be a set, and let $P(x)$ be a proposition depending on $x:S$. 
Then $\sum_{x:S} P(x)$ is a set. We also denote the latter set
as $\set{x:S \mid P(x)}$.
\end{lemma}

\begin{proof}
If $(x_1,p_1),(x_2,p_2) : \sum_{x:S} P(x)$, then by WHICH LEMMA
$(x_1,p_1)=(x_2,p_2)$ is equivalent to 
$\sum_{q:x_1=x_2} (\trp^P q\,p_1 = p_2)$. 
Since $P(x_2)$ is a proposition, using SEVERAL LEMMAS we get 
\[
\sum_{q:x_1=x_2} ({\trp}^P q\,p_1 = p_2) \equiv 
\sum_{q:x_1=x_2} \true \equiv (x_1=x_2).
\]

\end{proof}

\begin{lemma}\label{lem:eq_of_sets_is set}
If $X$ and $Y$ are sets, then $X=Y$ is a set.
\end{lemma}




\section{Equivalences; function extensionality}

\section{Universes and univalence}

\begin{theorem} theorem \end{theorem}

% Local Variables:
% fill-column: 144
% latex-block-names: ("lemma" "theorem" "remark" "definition" "corollary" "fact" "properties" "conjecture" "proof" "question" "proposition")
% End:
